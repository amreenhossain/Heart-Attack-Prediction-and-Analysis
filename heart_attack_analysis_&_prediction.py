# -*- coding: utf-8 -*-
"""Heart Attack Analysis & Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B87MNYk-c6syoTVFIeieUHG-LROBAy85
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
files.upload()

df = pd.read_csv('Heart attack analysis and prediction dataset final.csv')
df.head(5)

df.shape

df.isnull().sum()

"""Handling/Imputing missing values"""

df=df.dropna(axis=0,subset=['sex'])

df.shape

df.isnull().sum()

from sklearn.impute import SimpleImputer
impute=SimpleImputer(missing_values=np.nan,strategy='mean')
impute.fit(df[['chol']])
df['chol']=impute.transform(df[['chol']])

from sklearn.impute import SimpleImputer
impute=SimpleImputer(missing_values=np.nan,strategy='mean')
impute.fit(df[['thalachh']])
df['thalachh']=impute.transform(df[['thalachh']])

df.isnull().sum()

"""Splitting dataset"""

X=df.drop(columns='output',axis=1)
Y=df['output']

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, stratify=Y, random_state=43)

"""Feature Scaling

"""

#from pandas.core.groupby.groupby import Scalar
#from sklearn.preprocessing import MinMaxScaler
#Scalar=MinMaxScaler()
#Scalar.fit(X_train)

#X_train_Scaled=Scalar.transform(X_train)

#X_test_Scaled=Scalar.transform(X_test)

"""Training the model using Logistic Regression with the processed data"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, Y_train)
prediction=model.predict(X_test)
print ("print True heart attack chances       :", Y_test.values[:20])
print ("print Predicted heart attack chances  :", prediction[:20])

from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

print(f'Accuracy of the model: {round(accuracy_score(Y_test,prediction)*100,2)}%')

log_accr = round(accuracy_score(Y_test,prediction)*100,2)
print(log_accr)

"""F1-score, Precision and Recall

---


"""

print(classification_report(Y_test,prediction))

print(f'f1-score :{round(f1_score(Y_test, prediction),2)}')
print(f'precison :{round(precision_score(Y_test, prediction),2)}')
print(f'recall   :{round(recall_score(Y_test, prediction),2)}')

"""Testing an input data"""

testing_prediction_input=(46,1,0,120,249,0,0,144,0,0.8,2,0,3)
testing_prediction_input_as_numpy_array=np.asarray(testing_prediction_input)
reshaped_data=testing_prediction_input_as_numpy_array.reshape(1,-1)
predictn=model.predict(reshaped_data)
if(predictn[0]==0):
  print('The person has less chance of having a heart attack. ')
else:
  print('The person has more chance of having a heart attack. ')

print(f'Confusion Matrix: {(confusion_matrix(Y_test,prediction))}')

sns.set()
from mlxtend.plotting import plot_confusion_matrix

conf_matrix=confusion_matrix(y_true=Y_test,y_pred=prediction)
fig,ax=plot_confusion_matrix(conf_mat=conf_matrix,figsize=(6,6),cmap=plt.cm.GnBu)
plt.xlabel('prediction',fontsize=18)
plt.ylabel('Test',fontsize=18)
plt.title('Confusion Matrix',fontsize=18)
plt.show()

plt.figure(figsize=(16, 8))
sns.heatmap(df.corr(), annot=True,cmap='coolwarm',fmt='.2f')

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
df_clf=DecisionTreeClassifier(criterion='entropy',random_state=1)
df_clf.fit(X_train,Y_train)
y_pred=df_clf.predict(X_test)
dec_accr=accuracy_score(y_pred,Y_test)
print ('Accuracy:',dec_accr*100)